#################################################################################################
#
# Tools for the synthetic workload generation process proposed in the paper:
#
# - Marcus Carvalho, Francisco Brasileiro. 
#   Modelagem da Carga de Trabalho de Grades Computacionais Baseada no Comportamento dos Usuários. 
#   Submitted to: Simpósio Brasileiro de Redes de Computadores e Sistemas Distribuídos (SBRC), 2012.
#
# Last update: 05-Dec-2011
#
#################################################################################################

##
# Generates the synthetic workload using probability distributions listed in the input file.
#
# Inputs:
# - file.dits: input file generated by the model extraction process, with a list of distributions
#              for each attribute and trace.
# - k: number of clusters (groups) for each attribute
# - sites.per.trace: number of sites to create in the synthetic workload for each trace used
#                    in the model
# - users.per.trace: number os users that each created site comprises.
# - duration.sec: the duration of the synthetic workload in seconds.
# - rt.max: limit for the maximum runtime for a job (sum of tasks runtime for a job)
# - reduced.wl: if true, generates a job level workload ommiting task level information. Used if
#               a lower storage footprint is needed and high level information is enough.
# - transform.f: transformation function on the data generated. For instance, if a base-2 log 
#                transformation was used in the modeling phase, a base-2 exponential function
#                is needed in the workload generation.
##
GenerateWorkload <- function(file.dists="./wl_fitdist_best.txt", k=5, sites.per.trace=1, 
                             users.per.site=200, duration.secs=3600*24*30, rt.max=365*24, 
                             reduced.wl=FALSE, transform.f=function(x) 2^x) {
  require(foreach)
  require(doMC)
  registerDoMC()
                           
  dists.rfun <- list(normal=rnorm, lognormal=rlnorm, gamma=rgamma, exponential=rexp, 
                     weibull=rweibull)
  dists.qfun <- list(normal=qnorm, lognormal=qlnorm, gamma=qgamma, exponential=qexp, 
                     weibull=qweibull)
  
  buffer <- 10
  
  df <- read.table(file.dists, header=T)
  df <- subset(df, k == 5)
  
  p.i <- 0
  u.i <- 0
  
  for(trace in unique(df$Trace)) {
    is.first <- TRUE
    
    iat.dist <- subset(df, stats.attr=="bot_user_iat" & Trace==trace)
    iat.clusters <- sample(iat.dist$Cluster, sites.per.trace*users.per.site, 
                           prob=iat.dist$Fraction, replace=TRUE)
    
    rtsum.dist <- subset(df, stats.attr=="bot_runtime_sum" & Trace==trace)
    rtsum.clusters <- sample(rtsum.dist$Cluster, sites.per.trace*users.per.site, 
                             prob=rtsum.dist$Fraction, replace=TRUE) 
    
    trt.dist <- subset(df, stats.attr=="task_runtime" & Trace==trace)
    trt.clusters <- sample(trt.dist$Cluster, sites.per.trace*users.per.site, 
                           prob=trt.dist$Fraction, replace=TRUE) 
    
    cl.i <- 0
    for(peer in 1:sites.per.trace) {
      p.i <- p.i + 1
      for(user in 1:users.per.site) {
        gc() 
        cl.i <- cl.i + 1
        u.i <- u.i + 1
        df2 <- subset(df, Trace == trace)
        iat.dist <- subset(df2, stats.attr=="bot_user_iat" & Cluster==iat.clusters[cl.i])
        d <- as.character(iat.dist$distribution)
        
        t <- 0
        
        iat <- vector()
        st <- vector()
        while (t < duration.secs) {
          if (d != "exponential")
            iat <- c(iat, transform.f(dists.rfun[[d]](buffer, iat.dist$Param1, iat.dist$Param2)))
          else 
            iat <- c(iat, transform.f(dists.rfun[[d]](buffer, iat.dist$Param1)))
          
          st <- cumsum(iat)
          t <- st[length(st)]
        }
        njobs <- length(st)
        rtsum.dist <- subset(df2, stats.attr=="bot_runtime_sum" & Cluster==rtsum.clusters[cl.i])
        d <- as.character(rtsum.dist$distribution)
        
        rtsum <- vector()
        jobs.len <- 0
        while (jobs.len < njobs) {
          
          if (d != "exponential")
            rtsum <- c(rtsum, transform.f(dists.rfun[[d]](buffer, rtsum.dist$Param1, 
                                                          rtsum.dist$Param2)))
          else
            rtsum <- c(rtsum, transform.f(dists.rfun[[d]](buffer, rtsum.dist$Param1)))
          
          rtsum <- rtsum[rtsum <= rt.max]
          jobs.len <- length(rtsum)
          
        }
        length(rtsum) <- njobs
        ntasks <- vector() 
        
        rttask.dist <- subset(df2, stats.attr=="task_runtime" & Cluster==trt.clusters[cl.i])
        d <- as.character(rttask.dist$distribution)
        
        all_rt_tasks <- foreach(bot_runtime=rtsum, .combine=c) %do% {
          agg_runtime <- 0
          job_size <- 0
          rt_tasks <- vector(mode="numeric")
          task.i <- 1
          loop <- TRUE
          while(loop) {
            if (d != "exponential")
              rt_tasks <- c(rt_tasks, transform.f(dists.rfun[[d]](buffer, rttask.dist$Param1, 
                                                                  rttask.dist$Param2)))
            else
              rt_tasks <- c(rt_tasks, transform.f(dists.rfun[[d]](buffer, rttask.dist$Param1)))
  
            rt.sum <- cumsum(rt_tasks[(job_size+1):length(rt_tasks)]) + agg_runtime
            task.i <- max(0, min(which(rt.sum >= bot_runtime))-1)
            if (!is.infinite(task.i)) {
              length(rt_tasks) <- job_size + task.i + 1
              rt_tasks[length(rt_tasks)] <- ifelse(task.i > 0, bot_runtime-rt.sum[task.i], 
                                                   bot_runtime-agg_runtime)
              agg_runtime <- bot_runtime
              loop <- FALSE
            } else {
              agg_runtime <- rt.sum[length(rt.sum)]
            }
            
            job_size <- length(rt_tasks)
          }
          ntasks <- c(ntasks,job_size)
          return(rt_tasks)
        }
        uid <- paste("U",u.i,sep="")
        pid <- paste("P",p.i,sep="")
        iat.cid <- paste("C",iat.clusters[cl.i],sep="")
        rtsum.cid <- paste("C",rtsum.clusters[cl.i],sep="")
        rttask.cid <- paste("C", trt.clusters[cl.i],sep="") 
        if (reduced.wl) {
          wl <- subset(data.frame(SubmitTime=round(st), RunTime.sum=round(rtsum), 
                                  JobID=1:length(ntasks), BoTSize=ntasks, UserID=uid, PeerID=pid, 
                                  TraceID=trace, Cluster.IAT=iat.cid, Cluster.JRT=rtsum.cid, 
                                  Cluster.TRT=rttask.cid), SubmitTime <= duration.secs) 
        } else {
          wl <- subset(data.frame(SubmitTime=rep(round(st),ntasks), RunTime=round(all_rt_tasks), 
                                  JobID=rep(1:length(ntasks),ntasks), UserID=uid, PeerID=pid, 
                                  TraceID=trace, Cluster.IAT=iat.cid, Cluster.JRT=rtsum.cid, 
                                  Cluster.TRT=rttask.cid), SubmitTime <= duration.secs)
        }
        write.table(wl, paste('workload_clust_', sites.per.trace, 'spt_', users.per.site, "ups_",
                              trace,'.txt',sep=""), col.names=is.first, append=!is.first, 
                              quote=FALSE, row.names=FALSE)
        is.first <- FALSE
      }
    }
  }
}
